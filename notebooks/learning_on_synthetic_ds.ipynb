{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import shap\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import kendalltau, pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sys.path.insert(1, '/home/guilherme-resende/Desktop/mono2/utils')\n",
    "import qif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/synthetic_dataset_display_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides synthetic data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = df.sample(frac=0.8).index\n",
    "test_idx = df[~df.index.isin(train_idx)].index\n",
    "\n",
    "X_train = df.iloc[train_idx].drop(\"target\", axis=1)\n",
    "Y_train = df.loc[train_idx, \"target\"]\n",
    "\n",
    "X_test = df.iloc[test_idx].drop(\"target\", axis=1)\n",
    "Y_test = df.loc[test_idx, \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, Y_train)\n",
    "preds = xgb.predict(X_test)\n",
    "preds_proba = xgb.predict_proba(X_test)[:, 1:]\n",
    "\n",
    "df_test.loc[:, \"preds_proba\"] = preds_proba.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the model was always able to predict the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1_Score is {f1_score(Y_test, preds)}, whereas AUC is {roc_auc_score(Y_test, preds_proba)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the probabilities\n",
    "df_test[\"preds_proba\"] = (df_test[\"preds_proba\"] * 100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_leakage = qif.BayesLeakage(df_test)\n",
    "feature_names = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qif_values = []\n",
    "for feature in feature_names:\n",
    "    leakage = bayes_leakage.compute_flows(x=feature, y='preds_proba')\n",
    "    qif_values.append(max(leakage))\n",
    "\n",
    "qif_values = np.array(qif_values)\n",
    "qif_values = qif_values / qif_values.sum() # Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(9,7))\n",
    "\n",
    "plt.barh(feature_names, qif_values)\n",
    "plt.title(\"Feature Importance\", fontsize=16)\n",
    "plt.ylabel(\"Features Names\", fontsize=14)\n",
    "plt.xlabel(\"Normalized QIF Values\", fontsize=14)\n",
    "plt.yticks([\"f0\", \"f1\", \"f2\", \"f3\", \"f4\"], [\"F0\", \"F1\", \"F2\", \"F3\", \"F4\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(9,7))\n",
    "\n",
    "plt.boxplot(shap_values)\n",
    "plt.title(\"Feature Importance Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Features\", fontsize=14)\n",
    "plt.ylabel(\"SHAP Values\", fontsize=14)\n",
    "plt.xticks([1, 2, 3, 4, 5], [\"F0\", \"F1\", \"F2\", \"F3\", \"F4\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_values.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_coef, _ = kendalltau(shap_values, qif_values)\n",
    "p_coef, _ = pearsonr(shap_values, qif_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kendall:\", k_coef)\n",
    "print(\"Pearson:\", p_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
