{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "MAX_DEPTHS = [2,4,8,16]\n",
    "N_ESTIMATORS = [16,32,64,128,256]\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/adult_whole_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.set == \"train\"]\n",
    "df_train = df_train.drop(\"set\", axis=1)\n",
    "\n",
    "df_test = df[df.set == \"test\"]\n",
    "df_test = df_test.drop(\"set\", axis=1)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best parameters display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll consider dividing the training set into training and validation.\n",
    "# The final model will be trained on the entire training set and tested on test set\n",
    "Y = df_train.target.values\n",
    "X = df_train.drop(\"target\", axis=1)\n",
    "\n",
    "data = []\n",
    "for max_depth, n_estimators in itertools.product(MAX_DEPTHS, N_ESTIMATORS):\n",
    "    kf = KFold(n_splits=5)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "        model = XGBClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        model.fit(X.iloc[train_idx], Y[train_idx])\n",
    "\n",
    "        preds = model.predict(X.iloc[valid_idx])\n",
    "        preds_proba = model.predict_proba(X.iloc[valid_idx])[:, 1:]\n",
    "\n",
    "        f1 = f1_score(Y[valid_idx], preds)\n",
    "        auc = roc_auc_score(Y[valid_idx], preds_proba)\n",
    "\n",
    "        data.append([max_depth, n_estimators, fold, f1, auc])\n",
    "           \n",
    "df_results = pd.DataFrame(data, columns=[\"max_depth\", \"n_estimators\", \"fold\", \"f1_score\", \"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = (\n",
    "    df_results.groupby([\"max_depth\", \"n_estimators\"])\n",
    "    .agg(\n",
    "        mean_f1_score=(\"f1_score\", \"mean\"),\n",
    "        mean_auc=(\"auc\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        x=df_results.max_depth,\n",
    "        y=df_results.n_estimators,\n",
    "        z=df_results.mean_f1_score,\n",
    "        colorbar={\n",
    "            \"title\":\"Mean F1-Score\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Mean F1-Score for Each Parameter Combination\",\n",
    "    xaxis_title=\"Maximal Depth\",\n",
    "    yaxis_title=\"Number of Estimators\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "fig.update_yaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        x=df_results.max_depth,\n",
    "        y=df_results.n_estimators,\n",
    "        z=df_results.mean_auc,\n",
    "        colorbar={\n",
    "            \"title\":\"Mean F1-Score\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Mean AUC for Each Parameter Combination\",\n",
    "    xaxis_title=\"Maximal Depth\",\n",
    "    yaxis_title=\"Number of Estimators\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "fig.update_yaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = df_test.target.values\n",
    "X_test = df_test.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=4, n_estimators=128)\n",
    "model.fit(X, Y)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "preds_proba = model.predict_proba(X_test)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(Y_test, preds), roc_auc_score(Y_test, preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df_test[df_test.sex == 1]\n",
    "df_female = df_test[df_test.sex == 0]\n",
    "\n",
    "male_f1 = f1_score(df_male.target, model.predict(df_male.drop(\"target\", axis=1)))\n",
    "female_f1 = f1_score(df_female.target, model.predict(df_female.drop(\"target\", axis=1)))\n",
    "\n",
    "print(f\"Performance on Male Group: {male_f1}\")\n",
    "print(f\"Performance on Female Group: {female_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the SHAP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(shap_values, columns=X_test.columns).to_csv(\"../data/shap_test_adult.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
