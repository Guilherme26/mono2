{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import yaml\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from mnist import MNIST\n",
    "\n",
    "sys.path.insert(1, '/home/guilherme-resende/Desktop/mono2/utils')\n",
    "import qif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "MAX_DEPTHS = [2,4,8, 16]\n",
    "N_ESTIMATORS = [16,32,64,128,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = yaml.load(open(\"datasets.yaml\"))\n",
    "df = pd.read_csv(datasets[ds_name][\"path\"])\n",
    "\n",
    "df_train = df.loc[df.set == \"train\"].drop(\"set\", axis=1).reset_index(drop=True)\n",
    "df_test = df.loc[df.set == \"test\"].drop(\"set\", axis=1).reset_index(drop=True)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(\"targets\", axis=1)\n",
    "Y = df_train.targets\n",
    "\n",
    "X_test = df_test.drop(\"targets\", axis=1)\n",
    "Y_test = df_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the best parameters combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "%%time\n",
    "\n",
    "data = []\n",
    "for i, (max_depth, n_estimators) in enumerate(itertools.product(MAX_DEPTHS, N_ESTIMATORS), start=1):\n",
    "    kf = KFold(n_splits=5)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "        model = XGBClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "        model.fit(X.iloc[train_idx].values, Y[train_idx])\n",
    "\n",
    "        preds = model.predict(X.iloc[valid_idx].values)\n",
    "        preds_proba = model.predict_proba(X.iloc[valid_idx].values)\n",
    "\n",
    "        f1 = f1_score(Y[valid_idx], preds, average=\"weighted\")\n",
    "\n",
    "        data.append([max_depth, n_estimators, fold, f1])\n",
    "    \n",
    "    print(f\"{(i*100) // (len(MAX_DEPTHS) * len(N_ESTIMATORS))}% Complete.\")\n",
    "    \n",
    "df_results = pd.DataFrame(data, columns=[\"max_depth\", \"n_estimators\", \"fold\", \"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "df_results = (\n",
    "    df_results.groupby([\"max_depth\", \"n_estimators\"])\n",
    "    .agg(\n",
    "        mean_f1_score=(\"f1_score\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        x=df_results.max_depth,\n",
    "        y=df_results.n_estimators,\n",
    "        z=df_results.mean_f1_score,\n",
    "        colorbar={\n",
    "            \"title\":\"Mean F1-Score\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Mean F1-Score for Each Parameter Combination\",\n",
    "    xaxis_title=\"Maximal Depth\",\n",
    "    yaxis_title=\"Number of Estimators\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(type='category')\n",
    "fig.update_yaxes(type='category')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=8, n_estimators=128)\n",
    "model.fit(X.values, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test.values)\n",
    "preds_proba = model.predict_proba(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a Given Class to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in model.classes_:\n",
    "    target_idx = df_test[df_test.targets == target].index\n",
    "    df_test.loc[target_idx, \"preds_proba\"] = preds_proba[target_idx, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "for target in model.classes_:\n",
    "    df_target = df_test[df_test.targets == target]\n",
    "    X_target = df_target.drop([\"targets\", \"preds_proba\"], axis=1)\n",
    "    \n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_target.values)\n",
    "\n",
    "    shap_values = np.array(shap_values)[target]\n",
    "\n",
    "    data.append(shap_values.mean(axis=0))\n",
    "\n",
    "df_shap = pd.DataFrame(data)\n",
    "df_shap[\"digit\"] = model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = df_shap[df_shap.digit == 5].drop(\"digit\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(shap_values).reshape((28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate QIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "for i, target in enumerate(model.classes_, start=1):\n",
    "    df_target = df_test[df_test.targets == target]\n",
    "    \n",
    "    feature_names = X_test.columns\n",
    "    bayes_leakage = qif.BayesLeakage(df_target)\n",
    "    \n",
    "    qif_values = []\n",
    "    for feature in feature_names:\n",
    "        leakage = bayes_leakage.compute_flows(x=feature, y='preds_proba')\n",
    "        qif_values.append(leakage[0])\n",
    "    \n",
    "    data.append(qif_values)\n",
    "    \n",
    "    print(f\"{i / len(model.classes_) * 100} Complete.\")\n",
    "\n",
    "df_qif = pd.DataFrame(data)\n",
    "df_qif[\"digit\"] = model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize QIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qif_values = df_qif[df_qif.digit == 5].drop(\"digit\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(qif_values).reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Coeficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap[\"method\"] = \"SHAP\"\n",
    "df_qif[\"method\"] = \"QIF\"\n",
    "\n",
    "df = pd.concat([df_shap, df_qif])\n",
    "\n",
    "df.to_csv(f\"../data/results/{ds_name}_coeficients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
